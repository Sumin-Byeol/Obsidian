## 미니 배치, 배치 크기, 이터레이션 및 파이토치 데이터 로드 방법 요약

### 1. 미니 배치(Mini Batch)와 배치 크기(Batch Size)
- **미니 배치:** 대규모 데이터셋을 효율적으로 학습하기 위하여 전체 데이터를 작은 단위로 나누어 학습하는 개념입니다. 각 작은 단위를 미니 배치라고 합니다.
- **배치 크기:** 각 미니 배치에 포함된 샘플의 수입니다. 배치 경사 하강법 대신 미니 배치 경사 하강법을 사용하여 훈련 속도를 높이고 메모리 사용량을 줄일 수 있습니다.
- **배치 경사 하강법 vs 미니 배치 경사 하강법:** 전체 데이터를 한 번에 사용하는 배치 경사 하강법은 계산량이 많고 메모리 사용량이 크지만, 안정적으로 최적값에 수렴합니다. 미니 배치 경사 하강법은 전체 데이터의 일부만을 보고 수행하여 훈련 속도가 빠르며 메모리 효율이 좋습니다.

### 2. 이터레이션(Iteration)
- 한 에포크 내에서 이루어지는 매개변수(가중치) 업데이트 횟수입니다. 전체 데이터를 미니 배치로 나누었을 때, 이터레이션의 수는 전체 데이터셋을 모두 처리하기 위해 필요한 미니 배치의 개수와 같습니다.

### 3. 데이터 로드하기
- **파이토치 도구:** 텐서 데이터셋(`TensorDataset`)과 데이터 로더(`DataLoader`)를 사용하여 미니 배치 학습, 데이터 셔플, 병렬 처리를 쉽게 수행할 수 있습니다.
- **TensorDataset:** 텐서를 입력받아 데이터셋 형태로 변환합니다.
- **DataLoader:** 데이터셋과 배치 크기 등의 인자를 입력받아 학습에 사용할 데이터 배치를 생성합니다. `shuffle=True` 옵션을 사용하면 에포크마다 데이터셋의 순서를 섞어 학습의 효율성을 높일 수 있습니다.
