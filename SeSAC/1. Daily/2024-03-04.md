## 미니 배치, 배치 크기, 이터레이션 및 파이토치 데이터 로드 방법 요약

### 1. 미니 배치(Mini Batch)와 배치 크기(Batch Size)
- **미니 배치:** 대규모 데이터셋을 효율적으로 학습하기 위하여 전체 데이터를 작은 단위로 나누어 학습하는 개념입니다. 각 작은 단위를 미니 배치라고 합니다.
- **배치 크기:** 각 미니 배치에 포함된 샘플의 수입니다. 배치 경사 하강법 대신 미니 배치 경사 하강법을 사용하여 훈련 속도를 높이고 메모리 사용량을 줄일 수 있습니다.
- **배치 경사 하강법 vs 미니 배치 경사 하강법:** 전체 데이터를 한 번에 사용하는 배치 경사 하강법은 계산량이 많고 메모리 사용량이 크지만, 안정적으로 최적값에 수렴합니다. 미니 배치 경사 하강법은 전체 데이터의 일부만을 보고 수행하여 훈련 속도가 빠르며 메모리 효율이 좋습니다.

### 2. 이터레이션(Iteration)
- 한 에포크 내에서 이루어지는 매개변수(가중치) 업데이트 횟수입니다. 전체 데이터를 미니 배치로 나누었을 때, 이터레이션의 수는 전체 데이터셋을 모두 처리하기 위해 필요한 미니 배치의 개수와 같습니다.

### 3. 데이터 로드하기
- **파이토치 도구:** 텐서 데이터셋(`TensorDataset`)과 데이터 로더(`DataLoader`)를 사용하여 미니 배치 학습, 데이터 셔플, 병렬 처리를 쉽게 수행할 수 있습니다.
- **TensorDataset:** 텐서를 입력받아 데이터셋 형태로 변환합니다.
- **DataLoader:** 데이터셋과 배치 크기 등의 인자를 입력받아 학습에 사용할 데이터 배치를 생성합니다. `shuffle=True` 옵션을 사용하면 에포크마다 데이터셋의 순서를 섞어 학습의 효율성을 높일 수 있습니다.

### MLP의 설계와 문제점

- **입력 차원:** MLP 설계 시 입력 차원은 데이터 변수의 개수에 따라 결정됩니다. 예를 들어, 데이터 변수가 3개라면 입력 차원은 (None, 3)이 됩니다. 여기서 'None'은 배치 크기를 나타내며, 이는 모델이 어떠한 배치 크기도 처리할 수 있음을 의미합니다.
- **문제점:**
    - **인풋 값의 민감도:** 입력 데이터가 조금만 변화해도 인풋 값이 크게 변화합니다.
    - **데이터 형상의 무시:** MLP는 이미지의 공간적인 정보를 무시하고 모든 입력을 독립적으로 처리합니다.
    - **가중치의 양:** 학습해야 할 가중치의 수가 많아짐에 따라 모델의 복잡성과 과적합의 위험이 증가합니다.

### CNN의 구성과 장점

- **구성 요소:**
    
    - **Convolution 층:** 선언된 크기의 필터(Filter)를 이미지에 적용해 특징을 추출합니다.
    - **Pooling 층:** 추출된 특징 중 중요한 부분을 강조하여 데이터의 크기를 줄이고, 불필요한 정보를 제거합니다. 대표적인 방법으로는 Max Pooling과 Average Pooling이 있습니다.
    - **Fully Connected (FC) 층:** 최종적으로 추출된 특징을 바탕으로 분류를 수행합니다.
- **커널의 학습 가능성:** CNN에서 사용되는 커널들은 데이터로부터 특징을 학습할 수 있어야 합니다.
    
- **채널 정보의 일치:** 이미지의 채널 정보와 필터의 채널 정보가 일치해야 합니다.
    
- **Activation Map 생성:** 필터를 통해 Feature Map에서 더 도드라지는 특징을 강조합니다.
    
- **장점:**
    
    - **End-to-End 모델:** CNN은 특징 추출과 분류를 한 번에 학습할 수 있는 end-to-end 모델을 제공합니다.
    - **성능:** CNN은 이미지 분류 작업에서 높은 성능을 보이며, 특히 딥러닝 기반의 이미지 분류에서 강점을 가집니다.
    - **데이터 요구량:** 높은 성능을 달성하기 위해서는 대량의 데이터가 필요합니다.

CNN은 이미지와 같은 고차원 데이터에서 MLP보다 더 나은 성능을 보이는 경향이 있습니다. 이는 CNN이 이미지의 공간적 계층 구조를 활용하고, 중요한 특징만을 학습하기 때문입니다. 반면, MLP는 모든 연결이 중요하며, 이는 데이터의 공간적 구조를 무시하는 결과를 낳습니다.