
```python
- n :
n은 입력 크기(높이 혹은 너비),
- f :
f는 커널 크기,
- p :
p는 패딩 크기,
- s :
s는 스트라이드 크기입니다.
```

```python
#(n-dilation *(f-1)-1+2*p)/s+1
m = nn.Conv2d(16,33,(3,5), stride=(2,1), padding=(4,2), dilation=(3,1))
output = m(input)
print(output.shape)
```

### **문제점: 일반 신경망(FNN)의 한계**

1. **공간 정보의 손실**: FNN에서는 이미지를 일차원 배열로 변환하여 입력합니다. 이 과정에서 이미지의 공간적 연관성이 손실되며, 이는 정보의 손실로 이어집니다.
2. **파라미터 수의 증가**: 예를 들어, 1000x1000 크기의 컬러 이미지를 처리할 때 입력 노드의 수가 3,000,000개가 되며, 이는 파라미터 수의 급격한 증가를 초래합니다. 이는 과적합의 위험을 높이고, 모델의 효율성을 떨어뜨립니다.

### **CNN의 해결책**

CNN은 이러한 문제를 해결하기 위해 필터(또는 커널)라는 개념을 도입합니다. 이 필터들은 이미지 위를 이동하며 고유한 가중치를 사용하여 이미지의 부분적인 특성을 추출합니다. 이 과정을 통해 공간 정보를 유지하면서도 파라미터 수를 줄일 수 있습니다.

### CNN의 작동 방식

1. **합성곱(Convolutions)**: 이미지의 각 부분에 대해 필터를 적용하고, 필터와 이미지 부분 간의 내적을 계산하여 특성 맵을 생성합니다.
2. **비선형 활성화 함수**: 대부분의 경우, ReLU 활성화 함수를 사용하여 비선형성을 도입합니다.
3. **풀링(Pooling)**: 생성된 특성 맵의 크기를 줄이면서 중요한 정보를 유지합니다. 예를 들어, Max Pooling은 가장 큰 값을, Average Pooling은 평균 값을 선택합니다.
4. **평탄화(Flatten)**: 최종적으로 CNN의 출력을 일차원 배열로 변환하여, 전통적인 신경망의 입력으로 사용할 수 있습니다.

### **핵심 개념들**

- **Stride**: 필터가 이미지 위를 이동하는 거리입니다. Stride가 크면 특성 맵의 크기가 작아지고, 정보의 손실이 일어날 수 있습니다.
- **Padding**: 이미지의 가장자리에 픽셀을 추가하여, 필터가 이미지의 모든 부분을 고르게 처리할 수 있도록 합니다.
- **Activation Map**: 필터를 적용한 결과로, 이미지의 특정 특성을 나타내는 맵입니다.

### **결론**

CNN은 이미지의 공간적 구조를 이용하여 중요한 특성을 추출하고, 이를 기반으로 이미지를 분류하거나 다른 작업을 수행합니다. 필터, 스트라이드, 패딩과 같은 개념들을 통해 이미지 처리 작업에서 높은 효율성과 정확도를 달성합니다.