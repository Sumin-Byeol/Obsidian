# 자연어 처리(NLP, Natural Language Processing)

자연어 처리는 인간의 언어, 즉 **자연어**를 분석하고 처리하는 기술을 말합니다. 자연어는 정보 전달의 수단으로, 사람이 실제로 사용하는 언어의 형태입니다. 반면에, **인공어**는 컴퓨터가 자연어를 이해할 수 있도록 인위적으로 만들어낸 언어를 의미하며, 이에는 프로그래밍 언어 등이 포함됩니다.

자연어 처리의 목적은 인간의 언어를 컴퓨터가 이해하고, 컴퓨터가 처리한 정보를 다시 인간이 이해할 수 있는 언어로 변환하는 것입니다. 이는 인간과 컴퓨터 사이의 통역사 역할을 하는 과정이라고 할 수 있습니다.

자연어 처리는 크게 두 가지 주요 과정으로 나누어집니다:

## 1. Natural Language Understanding (NLU)

사람이 사용하는 자연어를 컴퓨터가 이해할 수 있는 형태로 바꾸는 과정입니다. 이 단계에서는 자연어의 의미를 파악하고, 해당 정보를 컴퓨터가 처리할 수 있는 데이터로 변환하는 작업을 수행합니다.

## 2. Natural Language Generation (NLG)

컴퓨터가 처리한 정보를 다시 사람이 이해할 수 있는 자연어로 변환하는 과정입니다. 이 단계에서는 컴퓨터가 분석하고 생성한 데이터를 인간이 이해하기 쉬운 언어로 표현하는 작업을 수행합니다.

자연어 처리 기술의 발전은 인간과 컴퓨터 간의 상호작용을 더 자연스럽고 효율적으로 만들어, 검색 엔진, 음성 인식 시스템, 기계 번역, 챗봇 등 다양한 응용 분야에서 혁신을 가져오고 있습니다.

# Foundation Model, Downstream Tasks, 그리고 Parameter Efficient Fine Tuning (PEFT)

## Foundation Models 개요

Foundation models은 대규모 데이터셋으로 사전 학습된 모델이며, 다양한 downstream tasks에 적용될 수 있는 범용성을 가집니다. 이 모델들은 업스트림(사전 학습) 과정에서 얻은 지식을 바탕으로, 특정 작업에 대해 뛰어난 성능을 발휘할 수 있습니다.

## Downstream Tasks 예시: Natural Language Inference (NLI)

- **목적**: 두 문장 간의 관계(모순, 중립, 함의)를 판별합니다.
- **예**: "The man is eating"과 "The man is not eating" 사이의 모순 관계를 판별합니다.

## 모델의 구성 요소

- **Elmo**: 양방향 RLM(Recursive Language Model) 사용, 문맥에 따른 단어 의미 파악에 탁월합니다.
- **Encoding의 특징 (분류)**: 입력 데이터를 변환하여 중요 특성을 추출, 분류 작업 수행.
- **Decoder의 특징 (생성)**: 인코딩된 정보를 바탕으로 텍스트 또는 다른 형태의 출력 생성.
- **Encoder, Decoder의 특징 (생성 및 분류)**: 번역기 같은 경우, 입력 텍스트를 인코딩해 특성을 추출하고 이를 다른 언어의 텍스트로 생성합니다.

## Parameter Efficient Fine Tuning (PEFT)

- **목적**: 사전 학습된 모델의 파라미터를 효율적으로 조정하여 특정 작업에 더욱 특화시키는 방법.
- **특징**: 모델의 크기나 복잡성을 크게 증가시키지 않고 성능 향상을 달성합니다.

## 연관된 개념들

- **Connected papers**: PEFT와 관련된 다양한 연구 논문 탐구.
- **Count vectors**: 텍스트에서 단어의 빈도수 계산, 간단하면서도 효과적인 정보 추출 방법.
- **형태소 종류**:
    - **실질형태소**: 의미를 가진 가장 작은 말의 단위 (예: 'eat', 'apple').
    - **형식형태소**: 문법적 기능을 하는 말의 단위, 예를 들어 조사, 어미 등 (예: '-ing', '의', '를').

## 언어 학습과 문장 데이터

문장 데이터는 언어 모델이 자연어의 문법, 의미, 문맥 등을 이해하고 생성하는 데 필요한 지식을 제공합니다. 이를 통해 모델은 언어의 복잡한 특성을 학습하게 됩니다.

# KoNLPy 내 분석기별 성능 차이 분석

KoNLPy는 한국어 처리를 위한 대표적인 파이썬 라이브러리 중 하나로, 여러 형태소 분석기를 제공합니다. 이 분석기들은 로딩시간과 실행시간에 차이를 보이며, 각각의 특성에 따라 적합한 상황에서 사용됩니다.

## 로딩시간 및 실행시간

- **로딩시간**: 형태소 분석기가 사용하는 사전 로딩을 포함하여 클래스를 읽어들이는 시간.
- **실행시간**: 10만 문자의 문서를 분석하는 데 소요되는 시간.

## 주요 형태소 분석기

1. **Kkma**
2. **Komoran**
3. **Hannanum**
4. **Okt(Twitter)**
5. **Mecab**

이들 분석기는 문자 개수가 많아질 때 실행시간이 기하급수적으로 증가하는 경향을 보입니다.

## 한국어 처리의 특징

- **접사 분리**: 한국어의 희소성을 낮추기 위해 접사를 분리합니다.
- **띄어쓰기 통일**: Tokenization을 수행하여 띄어쓰기를 통일합니다.

## 형태소 분석기 선택의 중요성

- **다양한 분석기**: Konlpy, Pororo, Khaiii 등 다양한 형태소 분석기가 존재합니다.
- **성능 비교**: 쉬운 문장에서는 성능이 비슷하지만, 신조어나 고유명사 처리 능력에서 차이를 보입니다.
- **적절한 분석기 선택**: 주어진 문제에 맞는 품사 태깅 방법을 제공하는 분석기를 선택하는 것이 중요합니다.

## 토큰 길이에 따른 Trade-off

- **짧은 토큰길이**
    - Vocabulary 크기 감소
    - 희소성 문제와 OOV(Out of Vocabulary) 문제 감소
    - Sequence 길이 증가 → 모델의 부담 증가
- **긴 토큰길이**
    - Vocabulary 크기 증가
    - 희소성 문제와 OOV 문제 증대
    - Sequence 길이 감소 → 모델의 부담 감소

## 토큰의 빈도에 따른 처리

- **높은 빈도의 토큰**: 하나의 토큰으로 나타내고 단어장에 저장합니다.
- **낮은 빈도의 토큰**: 더 잘게 쪼개어 각각의 토큰 빈도가 높게 나오도록 구성합니다.

**형태소로 분리된 단어들은 토큰이며, 이 토큰들의 나열을 토큰 시퀀스라고 합니다.** 이러한 이해를 바탕으로, 문제에 적합한 분석기 선택과 토큰화 방법을 결정하는 것이 한국어 NLP 작업의 핵심입니다.