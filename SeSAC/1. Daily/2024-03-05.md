# MLP의 한계

MLP의 문제점은 이미지가 조금만 변해도 입력 값이 크게 달라진다는 것이다. MLP는 데이터의 공간적인 정보를 무시하고 학습해야 할 가중치가 많다는 단점이 있다.

**fully connected layers의 단점**

- **인풋 값의 민감도:** 입력 데이터가 조금만 변화해도 인풋 값이 크게 변화한다.
- **데이터 형상의 무시:** MLP는 이미지의 공간적인 정보를 무시하고 모든 입력을 독립적으로 처리한다.
- **가중치의 양:** 학습해야 할 가중치의 수가 많아짐에 따라 모델의 복잡성과 과적합의 위험이 증가한다.

이를 해결하기 위해 이미지의 특징을 추출하고 이러한 변화에 대응하는 방법으로 CNN이 개발되었다.

학습을 통해서 특징을 추출 ⇒ CNN

~~CNN은 이미지 특징을 추출하기 때문에 이미지를 1차원 배열로 펼쳐서 모델입력으로 넣지 않아도 된다. 2차원 배열 그대로 입력에 넣어주면 된다. CNN을 거친 후에 1차원 배열로 만들기는 해야한다..~~

# CNN

CNN은 이미지의 공간적 구조를 보존하고, 여러 필터를 통해 특징을 추출한다.

CNN(Convolutional Neural Network)은 이미지의 공간적인 정보를 효과적으로 활용하고, **변화에 강한 특징을 학습**하기 위해 개발된 신경망 구조다. CNN은 MLP의 한계를 대체한다. MLP는 이미지를 일렬로 펼쳐서 처리하는데, 이는 공간적인 정보를 잃게 만든다. 반면, CNN은 이미지를 1차원으로 펼치지 않아도 된다.

CNN (Convolutional Neural Networks)는 이미지 처리에서 핵심적인 역할을 하는 신경망으로, 이미지의 고유 특성을 효과적으로 파악하고 활용하기 위해 고안되었습니다. 여기서는 CNN의 기본 개념과 작동 방식을 간단히 정리해보겠습니다.

### 문제점: 일반 신경망(FNN)의 한계

1. **공간 정보의 손실**: FNN에서는 이미지를 일차원 배열로 변환하여 입력합니다. 이 과정에서 이미지의 공간적 연관성이 손실되며, 이는 정보의 손실로 이어집니다.
2. **파라미터 수의 증가**: 예를 들어, 1000x1000 크기의 컬러 이미지를 처리할 때 입력 노드의 수가 3,000,000개가 되며, 이는 파라미터 수의 급격한 증가를 초래합니다. 이는 과적합의 위험을 높이고, 모델의 효율성을 떨어뜨립니다.

### CNN의 해결책

CNN은 이러한 문제를 해결하기 위해 필터(또는 커널)라는 개념을 도입합니다. 이 필터들은 이미지 위를 이동하며 고유한 가중치를 사용하여 이미지의 부분적인 특성을 추출합니다. 이 과정을 통해 공간 정보를 유지하면서도 파라미터 수를 줄일 수 있습니다.

#### CNN의 작동 방식

1. **합성곱(Convolutions)**: 이미지의 각 부분에 대해 필터를 적용하고, 필터와 이미지 부분 간의 내적을 계산하여 특성 맵을 생성합니다.
2. **비선형 활성화 함수**: 대부분의 경우, ReLU 활성화 함수를 사용하여 비선형성을 도입합니다.
3. **풀링(Pooling)**: 생성된 특성 맵의 크기를 줄이면서 중요한 정보를 유지합니다. 예를 들어, Max Pooling은 가장 큰 값을, Average Pooling은 평균 값을 선택합니다.
4. **평탄화(Flatten)**: 최종적으로 CNN의 출력을 일차원 배열로 변환하여, 전통적인 신경망의 입력으로 사용할 수 있습니다.

## CNN의 세 가지 층

CNN은 크게 세 가지 주요 층으로 구성된다:

- **Convolution 층** : 이 층에서는 다양한 크기의 필터를 이미지에 적용하여 특징을 추출한다. 각 필터는 이미지의 다른 특성을 감지하여 여러 피처맵을 생성한다.예를 들어, 세로 필터, 가로 필터, 대각선 필터 등을 사용하여 이미지의 세로선, 가로선, 대각선 등의 특징을 추출한다.
- **Pooling 층** : Convolution층을 통해 추출된 특징 맵(feature map)에서 중요한 정보만을 추려내는 과정이다. 이는 네트워크가 이미지의 작은 변화에 덜 민감하게 만들고 오버피팅을 줄이는 데 도움이 된다. 대표적으로 맥스 풀링(max pooling)과 에버리지 풀링(average pooling)이 있다.
- **Fully Connected(FC) 층 :** 앞서 추출된 특징들을 바탕으로 최종적으로 분류를 수행한다. 이 층은 일반적으로 신경망의 마지막 부분에 위치하며, 클래스에 속할 확률을 출력하는 데 사용된다.

### Convolution Layer

**Convolution layer Process**

- 입력 데이터의 처리: 컨볼루션 레이어에 입력되는 이미지는 여러 채널(RGB의 3채널 등)을 가진 2차원 데이터로, 각 채널은 별도의 2차원 매트릭스로 표현된다.
- 필터(커널)의 적용: 사전에 정의된 가중치를 가진 작은 2차원 매트릭스인 필터가 이미지 위를 이동하며 적용된다. 이 필터들은 이미지의 특정 특징을 감지하기 위해 사용된다.
- 요소별 곱셈과 합산: 필터는 이미지의 각 위치에서 해당 부분과 요소별 곱을 수행한 후 결과를 합산하여 피처맵의 하나의 값으로 저장한다.
- 스트라이드의 적용: 필터가 이미지를 스캔하는 동안 스트라이드(stride)를 사용하여 한 번에 이동하는 픽셀의 수를 결정한다. 스트라이드가 1이면, 필터는 한 번에 한 픽셀씩 이동하며 전체 이미지를 스캔한다.
- 피처맵의 생성: 필터가 이미지 전체에 적용되면서 생성된 결과를 피처맵에 순차적으로 저장한다. 이 피처맵은 입력 이미지에서 중요한 특징을 나타낸다.
- 비선형 활성화 함수: 컨볼루션 연산 후에는 피처맵에 비선형 활성화 함수를 적용하여 모델이 비선형 문제를 해결할 수 있도록 한다. 가장 일반적으로 사용되는 활성화 함수는 ReLU이다.

convolution layer에서 28_28⇒26_26 로 사이즈가 바뀌는 이유

**padding(패딩)**

- **패딩을 사용하는 이유 :**

이미지를 입력으로 받아 필터를 적용하면 활성화 맵(Activation map)이 생성된다. 이 과정을 반복하면서 새로운 필터를 적용하면서 Activation map을 계속 생성하게 된다. 이 과정을 거칠수록 Activation map의 크기는 점차적으로 줄어든다. 이러한 현상 때문에, 네트워크의 레이어를 깊게 쌓으면서 분류를 위한 필터 맵의 수가 적어진다. 이런 문제를 해결하기 위해 패딩(Padding)을 적용한다.

- **패딩 사용 방법 및 장점**

Padding은 필터를 적용하기 전에 입력 데이터 주변에 0으로 채워넣는 과정이다. 패딩은 filter를 override하기 전에 입력데이터에 padding을 적용해서 activation map의 크기를 유지시켜준다. 이렇게 함으로써 입력과 특성 맵의 크기를 동일하게 유지할 수 있고, 이미지의 가장자리에 위치한 픽셀 정보의 손실을 방지하며, 패딩으로 채워진 값은 실제로는 0이므로 계산에 영향을 미치지 않는다.

### Pooling Layer

**Pooling Layer 사용 이유**

- 데이터의 차원을 축소하여 표현을 간결하고 관리하기 쉽게 만든다.
- 각각의 activation map에 독립적으로 적용되어 효율적인 처리를 가능하게 한다.

**맥스(Max) 풀링:**

receptive field 내에서 가장 큰 값을 선택해 새로운 feature map을 만드는 과정이다.

- 각 리셉티브 필드(피처맵의 지역적인 영역)에서 가장 큰 값을 선택하여 다음 레이어로 전달한다.
- 일반적으로 2x2 크기의 풀링 필터를 사용하고, 이 경우 스트라이드도 2로 설정하여 겹치지 않게 한다.
- 결과적으로 피처맵의 크기는 가로와 세로 각각 절반으로 줄어듭니다.

```python
**Max Pooling를 쓰는 이유 :** 
- Convolution layer를 통해 추출된 feature map에서 중요한 정보를 강조하고 데이터의 크기를 줄임으로써 overfitting을 감소시킨다.
- Pooling layer는 parameter가 없으므로, network의 복잡도를 줄이고 overfitting 위험을 낮춘다.
- parameter가 없기 때문에 계산량과 하드웨어 자원(에너지)을 절약하며, 처리 속도를 향상시킨다.
- stride(스트라이드)를 사용하여 오버랩 없이 특정 간격으로 pooling을 수행하여 feature map을 축소한다.
```

**에버리지(Average) 풀링:**

receptive field 내의 값들의 평균을 계산하여 새로운 feature map을 만드는 과정이다.

- receptive field 내의 값들의 평균을 계산하여 평균값을 다음 레이어로 전달한다.
- 에버리지 풀링은 영역 전체의 평균적인 특징을 다음 레이어로 전달하는 효과를 가진다..

---

### 핵심 개념들

- **Stride**: 필터가 이미지 위를 이동하는 거리입니다. Stride가 크면 특성 맵의 크기가 작아지고, 정보의 손실이 일어날 수 있습니다.
- **Padding**: 이미지의 가장자리에 픽셀을 추가하여, 필터가 이미지의 모든 부분을 고르게 처리할 수 있도록 합니다.
- **Activation Map**: 필터를 적용한 결과로, 이미지의 특정 특성을 나타내는 맵입니다.

### 결론

CNN은 이미지의 공간적 구조를 이용하여 중요한 특성을 추출하고, 이를 기반으로 이미지를 분류하거나 다른 작업을 수행합니다. 필터, 스트라이드, 패딩과 같은 개념들을 통해 이미지 처리 작업에서 높은 효율성과 정확도를 달성합니다.

```python
- n :
n은 입력 크기(높이 혹은 너비),
- f :
f는 커널 크기,
- p :
p는 패딩 크기,
- s :
s는 스트라이드 크기입니다.
```

```python
#(n-dilation *(f-1)-1+2*p)/s+1
m = nn.Conv2d(16,33,(3,5), stride=(2,1), padding=(4,2), dilation=(3,1))
output = m(input)
print(output.shape)
```

### **문제점: 일반 신경망(FNN)의 한계**

1. **공간 정보의 손실**: FNN에서는 이미지를 일차원 배열로 변환하여 입력합니다. 이 과정에서 이미지의 공간적 연관성이 손실되며, 이는 정보의 손실로 이어집니다.
2. **파라미터 수의 증가**: 예를 들어, 1000x1000 크기의 컬러 이미지를 처리할 때 입력 노드의 수가 3,000,000개가 되며, 이는 파라미터 수의 급격한 증가를 초래합니다. 이는 과적합의 위험을 높이고, 모델의 효율성을 떨어뜨립니다.

### **CNN의 해결책**

CNN은 이러한 문제를 해결하기 위해 필터(또는 커널)라는 개념을 도입합니다. 이 필터들은 이미지 위를 이동하며 고유한 가중치를 사용하여 이미지의 부분적인 특성을 추출합니다. 이 과정을 통해 공간 정보를 유지하면서도 파라미터 수를 줄일 수 있습니다.

### CNN의 작동 방식

1. **합성곱(Convolutions)**: 이미지의 각 부분에 대해 필터를 적용하고, 필터와 이미지 부분 간의 내적을 계산하여 특성 맵을 생성합니다.
2. **비선형 활성화 함수**: 대부분의 경우, ReLU 활성화 함수를 사용하여 비선형성을 도입합니다.
3. **풀링(Pooling)**: 생성된 특성 맵의 크기를 줄이면서 중요한 정보를 유지합니다. 예를 들어, Max Pooling은 가장 큰 값을, Average Pooling은 평균 값을 선택합니다.
4. **평탄화(Flatten)**: 최종적으로 CNN의 출력을 일차원 배열로 변환하여, 전통적인 신경망의 입력으로 사용할 수 있습니다.

### **핵심 개념들**

- **Stride**: 필터가 이미지 위를 이동하는 거리입니다. Stride가 크면 특성 맵의 크기가 작아지고, 정보의 손실이 일어날 수 있습니다.
- **Padding**: 이미지의 가장자리에 픽셀을 추가하여, 필터가 이미지의 모든 부분을 고르게 처리할 수 있도록 합니다.
- **Activation Map**: 필터를 적용한 결과로, 이미지의 특정 특성을 나타내는 맵입니다.

### **결론**

CNN은 이미지의 공간적 구조를 이용하여 중요한 특성을 추출하고, 이를 기반으로 이미지를 분류하거나 다른 작업을 수행합니다. 필터, 스트라이드, 패딩과 같은 개념들을 통해 이미지 처리 작업에서 높은 효율성과 정확도를 달성합니다.